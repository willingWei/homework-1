{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “火炬上的深度学习\"第一次大作业\n",
    "\n",
    "在这个作业中，你需要半独立地利用人工神经网络搭建一个手写数字识别器\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"简单的 LeNet-5类型的卷积神经网络模型，MNIST例子.\n",
    "\"\"\"\n",
    "\n",
    "#所有依赖包\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#定义一系列常数\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/' #图像数据如果没下载，可以从这个地址下载\n",
    "WORK_DIRECTORY = 'data' #存储的路径名\n",
    "IMAGE_SIZE = 28 #每张图片的大小尺寸\n",
    "NUM_CHANNELS = 1  #每张图片的通道数\n",
    "PIXEL_DEPTH = 255 #像素的深度0-255\n",
    "NUM_LABELS = 10 #手写数字，一共十种\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取MINST图形文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下载图像文件，如果文件已经存在，那么就不下载。\n",
    "def maybe_download(filename):\n",
    "    \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "    if not os.path.isdir(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "# Get the data.\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    # filename: 文件存放的路径，num_images: 读入的图片个数\n",
    "    \"\"\"将图像解压缩展开，读入成一个4维的张量： [image index（图像的编码）, y（纵坐标）, x（横坐标）, channels（通道）].\n",
    "    我们将数组中的数值范围从原来的[0, 255]降低到了[-0.5, 0.5]范围内\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"将label的数据文件解压缩，并将label读成64位的整数\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n",
    "\n",
    "# 将数据解压缩并存储到数组中，60000张图片，60000个label，测试集中有10000张图片\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_X = train_data.reshape(len(train_data), -1)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "train_Y = train_labels\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_X = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "test_Y = test_labels\n",
    "train_X.shape, train_Y.shape\n",
    "\n",
    "# train_X, train_Y 中分别存储的是向量化的训练数据与标签\n",
    "# test_X, test_Y 中分别存储的是向量化的测试数据与标签\n",
    "# train_X的维度是60000个样本，784个分量的图像向量\n",
    "# test_X的维度是10000个样本，784个分量的图像向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在这里写下你自己的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步：定义神经网络，提示，可以使用简单的torch.nn.SequentialModel\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示：需要考虑好网络有几层，每一层有多少个节点\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 300),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(300, 10),\n",
    "    torch.nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "# 问题：如果要增加新的神经网络层怎么办？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步：构造损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步：开始训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.23686\n",
      "100 1.5372\n",
      "200 1.51618\n",
      "300 1.50515\n",
      "400 1.49764\n",
      "500 1.49227\n",
      "600 1.48829\n",
      "700 1.48515\n",
      "800 1.48256\n",
      "900 1.48044\n"
     ]
    }
   ],
   "source": [
    "# 提示：有两重循环，最外面层是多少次的训练，里层为对数据批次（batch）的循环\n",
    "losses = []\n",
    "# 神经网络训练循环\n",
    "batch_size = 128\n",
    "for i in range(1000):\n",
    "    # 每128个样本点被划分为一个撮，在循环的时候一撮一撮地读取\n",
    "    batch_loss = []\n",
    "    # start和end分别是提取一个batch数据的起始和终止下标\n",
    "    for start in range(0, len(train_X), batch_size):\n",
    "        end = start + batch_size if start + batch_size < len(train_X) else len(train_X)\n",
    "        xx = Variable(torch.FloatTensor(train_X[start:end])) #从训练数据train_X中提取数据\n",
    "        yy = Variable(torch.LongTensor(train_Y[start:end]))  #从训练数据train_Y中提取标签，注意标签数据为整数，因此相应的tensor也要为long\n",
    "        predict = net(xx) #用神经网络进行预测\n",
    "        loss = cost(predict, yy) #计算损失函数（交叉熵）\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss.backward() #开始反向传播\n",
    "        optimizer.step() #开始更新梯度\n",
    "        batch_loss.append(loss.data.numpy())\n",
    "    \n",
    "    # 每隔100步输出一下损失值（loss）\n",
    "    if i % 100==0:\n",
    "        losses.append(np.mean(batch_loss))\n",
    "        print(i, np.mean(batch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请在这里写下你自己的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17e83a23668>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJARBBoCEIMgAkBAEGQASgiADQEL8Pxef9ereZDhgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e837de908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 请绘制上面训练过程的损失函数曲线，以及'''错误率曲线'''！！！\n",
    "plt.plot(np.arange(len(losses))*100,losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四步：在测试集上测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个专门计算分类错误率的函数，它的基本思想是，对于预测向量predictions的每一行，\n",
    "# 取最大的那个元素的下标，与标签labels中的元素做比较\n",
    "def error_rate(predictions, labels):\n",
    "#    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，labels是数据之中的正确答案\"\"\"\n",
    "    predictions = np.argmax(predictions, 1)\n",
    "    return 100.0 - (\n",
    "      100.0 *\n",
    "      np.sum( predictions == labels) /\n",
    "      predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.61\n",
      "2 2.63371150729\n",
      "3 2.64778325123\n",
      "4 2.64143094842\n",
      "5 2.63490725126\n",
      "6 2.64957264957\n",
      "7 2.63214904679\n",
      "8 2.65817223199\n",
      "9 2.62923351159\n",
      "10 2.61075949367\n",
      "11 2.56880733945\n",
      "12 2.51396648045\n",
      "13 2.48109640832\n",
      "14 2.48320537428\n",
      "15 2.44883040936\n",
      "16 2.46287128713\n",
      "17 2.36418511066\n",
      "18 2.31339468303\n",
      "19 2.24792099792\n",
      "20 2.20665961945\n",
      "21 2.21774193548\n",
      "22 2.21553610503\n",
      "23 2.21325167038\n",
      "24 2.15419501134\n",
      "25 2.10739030023\n",
      "26 2.10294117647\n",
      "27 2.12829736211\n",
      "28 2.13936430318\n",
      "29 2.0885286783\n",
      "30 2.11513994911\n",
      "31 1.98051948052\n",
      "32 1.90649867374\n",
      "33 1.84620596206\n",
      "34 1.74861495845\n",
      "35 1.69971671388\n",
      "36 1.66666666667\n",
      "37 1.61350148368\n",
      "38 1.59574468085\n",
      "39 1.53816199377\n",
      "40 1.45766773163\n",
      "41 1.49590163934\n",
      "42 1.49410774411\n",
      "43 1.51384083045\n",
      "44 1.5346975089\n",
      "45 1.55677655678\n",
      "46 1.50943396226\n",
      "47 1.48346303502\n",
      "48 1.38052208835\n",
      "49 1.34854771784\n",
      "50 1.34120171674\n",
      "51 1.38888888889\n",
      "52 1.41129032258\n",
      "53 1.25598086124\n",
      "54 1.27487562189\n",
      "55 1.29533678756\n",
      "56 1.35135135135\n",
      "57 1.41242937853\n",
      "58 1.44230769231\n",
      "59 1.51397515528\n",
      "60 1.5114379085\n",
      "61 1.59482758621\n",
      "62 1.68795620438\n",
      "63 1.74418604651\n",
      "64 1.75619834711\n",
      "65 1.76991150442\n",
      "66 1.84523809524\n",
      "67 1.93298969072\n",
      "68 1.96629213483\n",
      "69 2.16049382716\n",
      "70 2.39726027397\n",
      "71 2.69230769231\n",
      "72 2.63157894737\n",
      "73 3.0612244898\n",
      "74 3.65853658537\n",
      "75 4.54545454545\n",
      "76 5.5\n",
      "77 5.14705882353\n",
      "78 3.47222222222\n",
      "79 0.0\n",
      "平均错误率：2.1146%\n"
     ]
    }
   ],
   "source": [
    "# 分多个batch计算测试结果\n",
    "errors = []\n",
    "losses = []\n",
    "i = 0\n",
    "for start in range(0, len(test_X), batch_size):\n",
    "    end1 = start + batch_size if start + batch_size < len(test_X) else len(test_X)\n",
    "    i += 1\n",
    "    x = Variable(torch.FloatTensor(test_X[start:end]))\n",
    "    y = Variable(torch.LongTensor(test_Y[start:end]))\n",
    "    predictions = net(x)\n",
    "    loss = cost(predictions, y)\n",
    "    err_rate = error_rate(predictions.data.numpy(), y.data.numpy())\n",
    "    errors.append(err_rate)\n",
    "    losses.append(loss.data.numpy())\n",
    "    print(i, err_rate)\n",
    "\n",
    "print('平均错误率：%.4f%%'%np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用单个图像进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17e8369a048>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e8206d0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#随便从数据集中读入一张图片，并绘制出来\n",
    "idx = 100\n",
    "muteimg = test_data[idx, 0, :, :]\n",
    "plt.imshow(muteimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算识别结果\n",
    "x = Variable(torch.FloatTensor(test_X[idx, :].reshape(1, -1)))\n",
    "predict = net(x)\n",
    "np.argmax(predict.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 升级版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你已经运行跑通上面的所有代码，那么请你尝试对其进行更改，让测试集上面的识别错误率进一步下降，看看能不能到1%以下\n",
    "\n",
    "提示：可以考虑增加层的深度\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
